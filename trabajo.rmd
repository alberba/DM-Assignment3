---
title: "Assignment 3"
author: "Santiago Rattenbach, Angel Jiménez, Albert Salom"
date: "21/11/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Libraries}
# Load the required libraries
library(ggplot2)
library(GGally)
library(e1071)
library(class)
library(gmodels)
library(tree)
library(FSelector)
library(partykit)
library(party)
library(RWeka)
```


```{r}
data <- read.csv("./loan_data.csv", header=TRUE, stringsAsFactors=TRUE)
str(data)
```

As we can see, the dataset contains 45,000 observations and 14 variables. The variables are as follows:

1. person age: Age of the person (numeric)
2. person gender: Gender of the person (categorical: female, male)
3. person education: Highest education level (categorical: Associate, Bachelor, Doctorate, High School, Master)
4. person income: Annual income (numeric)
5. person emp exp: Years of employment experience (integer)
6. person home ownership: Home ownership status (categorical: MORTGAGE, OTHER, OWN, RENT)
7. loan amnt: Loan amount requested (numeric)
8. loan intent: Purpose of the loan (categorical: DEBTCONSOLIDATION, EDUCATION, HOME-IMPROVEMENT, MEDICAL, PERSONAL, VENTURE)
9. loan int rate: Loan interest rate (numeric)
10. loan percent income: Loan amount as a percentage of annual income (numeric)
11. cb person cred hist length: Length of credit history in years (numeric)
12. credit score: Credit score of the person (integer)
13. previous loan defaults on file: Indicator of previous loan defaults (categorical: No, Yes)


## The Data

### Target Variable

- **loan_status**: The status of the loan (integer 1 = approved; 0 = rejected)

```{r}
# Crear el gráfico de barras
ggplot(data, aes(x = factor(loan_status, labels = c("Rechazado", "Aprobado")))) +
  geom_bar(fill = "skyblue") +
  labs(title = "Distribution of loan approval status",
       x = "Loan status",
       y = "Quantity")
```
Most loans end up getting denied, we aim to understand why that is the case and build a model that predicts the outcome as much as possible.

### Independent Variables

Antes de comenzar con el entrenamiento, es importante analizar cada una de las variables independientes para entender sus valores, su distribución y relación con la variable objetivo.

```{r}
summary(data)
```


#### Numerical

- person_age: Este dataset abarca personas adultas, por tanto la edad mínima es 20 años. La media está entre los 27.76 años, por tanto la mayor parte de muestras del conjunto está formada por gente joven. Por otro lado, la edad máxima es 144 años, lo cual es un valor atípico. En este caso, hemos considerado que la edad máxima aceptable es 122 años, ya que es la edad más longeva registrada en la historia. Por tanto, eliminaremos las observaciones con edades superiores a 122 años.

```{r}
data <- subset(data, person_age <= 50)
```

- person_income: Este dataset abarca entre valores anuales de 8.000$ y 7.200.766$. Supondremos que las muestras con ingresos anuales mayores a 500.000$ no tendrían ninguna dificultad para pedir un préstamo con las dimensiones de este dataset

```{r}
data <- subset(data, person_income < 250000)
```

- person_emp_exp: Esta variable tiene un rango de 0 a 123 años. Este último valor es bastante atípico, además considerando que la edad máxima que hemos aceptado es de 122 años. 
Igualmente, al eliminar las observaciones con edades superiores a 122 años, también eliminamos las observaciones con años de experiencia laboral superiores a 122 años.
- loan_amnt: El importe de los préstamos varían entre 500$ y 35.000$. Inicialmente, no parece haber ningún dato atípico
- loan_int_rate: La tasa del préstamo varía entre el 5.42% y el 20%. Nada preocupante
- loan_percent_income: Como podemos observar, hay muestras donde el porcentaje del préstamo sobre los ingresos anuales es 0%, algo imposible. Veamos cuantas muestras tienen un 0%

```{r}
aux <- subset(data, loan_percent_income == 0)
aux <- subset(aux, person_income > 2000000)
head(aux)
```

Vemos que hay 6 muestras con un porcentaje de préstamo sobre los ingresos anuales de 0%. Esto es imposible, ya que si el porcentaje es 0%, el préstamo es 0$.
Eliminaremos las muestras que concuerden con estas condiciones.

```{r}
data <- subset(data, loan_percent_income != 0)
```

- cb_person_cred_hist_length: La longitud del historial crediticio varía entre 2 y 30 años. No parece haber ningún valor atípico.
- credit_score: La puntuación crediticia varía entre 390 y 850. No parece haber ningún valor atípico.

Veamos como queda el dataset tras eliminar los valores atípicos:

```{r}
summary(data)
```
```{r}
# Lista de variables numéricas
numeric <- c('person_age', 'person_income', 'person_emp_exp', 'loan_amnt', 
                    'loan_int_rate', 'loan_percent_income', 
                    'cb_person_cred_hist_length', 'credit_score')


# Distribuciones de las variables numéricas:
for (n in numeric) {
  print(
    ggplot(data, aes(x = !!sym(n))) +
      geom_histogram(fill = "lightblue", color = "white", bins = 30) +
      labs(title = paste("Distribución de", n), x = n, y = "Frecuencia") +
      theme_minimal()
  )
}
```

Como podemos observar, menos el credit_score, la mayoría de las variables numéricas no siguen una distribución normal y se extienden por la derecha. Esto puede ser un problema para los modelos de regresión, ya que estos asumen que las variables siguen una distribución normal. Por tanto, es posible que tengamos que transformar estas variables para que sigan una distribución normal.

#### Categorical

```{r}
# Miramos los datos de las variables categóricas:
cat <- c('person_gender', 'person_education', 'person_home_ownership', 'loan_intent', 'previous_loan_defaults_on_file')

for (var in cat) {
  print(
    ggplot(data, aes_string(x = var)) +
      geom_bar(fill = "coral1") +
      labs(title = paste("Distribución de", var), x = var, y = "Frecuencia") +
      theme_minimal()
  )
}
```

- gender: As we can see, the majority of the applicants are male, however, the difference is not very significant so there isn't much information to be gained from these values.
- education: The number of applicants with a master's degree is approximately half the number of people in any category, except for those with a doctorate, who are significantly fewer. This variable may be useful in predicting the loan status.
Esto puede indicarnos que las personas con un nivel educativo más alto son más propensas a solicitar un préstamo.
- home ownership: The majority of applicants are renters, followed mortgage holders. There are few applicants who own their homes and even fewer who own other types of homes. This variable may also be useful in predicting the loan status.
- loan intent: The most common loan intents are both education and medical bills, followed by debt consolidation, venture and personal loans. Fewer people take out loans for home improvement. This variable may also be useful in predicting the loan status.

### Data Correlations

#### Numerical Variables

```{r}
# Aplicamos el ggpairs para ver las relaciones entre las variables numéricas:
# ggpairs(data)

numeric_Corr <- data[, c('person_age', 'person_income', 'person_emp_exp',
                        'loan_amnt', 'loan_int_rate', 'loan_percent_income',
                        'cb_person_cred_hist_length', 'credit_score')]

ggcorr(numeric_Corr, label = TRUE)
```
Como podemos observar, 'credit_score' y 'loan_int_rate', apenas influyen, ya que sus correlaciones con las otras variables son prácticamente nulas, por tanto procedemos a eliminarlas.
Por otra parte, se observa que 'person_age', 'person_emp_exp' y 'cb_person_cred_hist_length' tienen una correlación muy alta entre ellas, por tanto eliminaremos 'person_emp_exp' y 'cb_person_cred_hist_length' para evitar la multicolinealidad.

```{r}
names(data)
```

```{r}
# Eliminar por posición
data_Mod <- data[, -c(5, 9, 11, 12)]

# Verificar las columnas restantes
names(data_Mod)
```

```{r}
# Comparar las correlaciones de las variables numéricas restantes:
ggcorr(data_Mod, label = TRUE, label_round = 2)
```



### Bivariate Analysis

#### Numeric Variables

```{r}
# Creamos los plots para las 6 varaibles restantes: 
p1 <- ggplot(data_Mod) + geom_boxplot(aes(x = factor(loan_status), y = person_age), fill = "violet", alpha = 0.6) +
  theme(axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status vs Person Age", x = "Loan Status", y = "Person Age") +
  theme_minimal()

print(p1)
```

```{r}
p2 <- ggplot(data_Mod) + geom_boxplot(aes(x = factor(loan_status), y = person_income), fill = "#FFB6C1", alpha = 0.6) +
  theme(axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status vs Person Income", x = "Loan Status", y = "Person Income") +
  theme_minimal()

print(p2)
```

```{r}
p3 <- ggplot(data_Mod) + geom_boxplot(aes(x = factor(loan_status), y = loan_amnt), fill = "violet", alpha = 0.6) +
  theme(axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status vs Loan Amount", x = "Loan Status", y = "Loan Amount") +
  theme_minimal()

print(p3)
```

```{r}
p4 <- ggplot(data_Mod) + geom_boxplot(aes(x = factor(loan_status), y = loan_percent_income), fill = "#FFDAB9", alpha = 0.6) +
  theme(axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status vs Loan Percent Income", x = "Loan Status", y = "Loan Percent Income") +
  theme_minimal()

print(p4)
```


#### Categorical Variables

```{r}
# Crear gráficos para cada variable categórica:
p1 <- ggplot(data_Mod) +
  geom_violin(aes(x = person_gender, y = loan_status), fill = "lightblue") +
  theme(axis.text = element_text(size = 10),
        axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status by Person Gender", x = "Person Gender", y = "Loan Status")

print(p1)
```

```{r}
p2 <- ggplot(data_Mod) +
  geom_violin(aes(x = person_education, y = loan_status), fill = "lightpink") +
  theme(axis.text = element_text(size = 10),
        axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status by Person Education", x = "Person Education", y = "Loan Status")

print(p2)
```

```{r}
p3 <- ggplot(data_Mod) +
  geom_violin(aes(x = person_home_ownership, y = loan_status), fill = "lightgreen") +
  theme(axis.text = element_text(size = 10),
        axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status by Person Home Ownership", x = "Person Home Ownership", y = "Loan Status")

print(p3)
```

```{r}
p4 <- ggplot(data_Mod) +
  geom_violin(aes(x = loan_intent, y = loan_status), fill = "lavender") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status by Loan Intent", x = "Loan Intent", y = "Loan Status")

print(p4)
```

```{r}
# Barras para la distribución de previous_loan_defaults_on_file
ggplot(data_Mod, aes(x = previous_loan_defaults_on_file)) +
  geom_bar(fill = "coral1") +
  labs(
    title = "Distribución de Previous Loan Defaults",
    x = "Previous Loan Defaults",
    y = "Frecuencia"
  ) +
  theme_minimal()

p5 <- ggplot(data_Mod) +
  geom_violin(aes(x = previous_loan_defaults_on_file, y = loan_status), fill = "peachpuff") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 8.5)) +
  labs(title = "Loan Status by Previous Loan Defaults", x = "Previous Loan Defaults", y = "Loan Status")

print(p5)
```

### Missing Value Analysis

To find missing values in the dataset, we can use the `is.na()` function in R. 

```{r}
colSums(is.na(data_Mod))
```

Como podemos ver, en ninguna de las variables hay valores faltantes, lo que nos hace ahorrarnos el paso de tener que tratar estos valores

### Key Features

A partir de estos violin plots se puede observar una peculiaridad en el atributo previous_loan_defaults_on_file,
que indica si el solicitante ha tenido préstamos anteriores con impagos. En caso de ser así, el prestamo es siempre rechazado, entonces este atributo es clave para predecir el resultado del préstamo.

Analizando la correlación entre las variables, se observa que tanto el person_income como el loan_amnt y el loan_percent_income tienen una correlación elevada,
por tanto son también variables importantes a tener en cuenta. 

### PreProcessing Data

#### Checking Normality (Skewness)

```{r}
skewness(data_Mod$person_age)
```
```{r}	
ggplot(data_Mod, aes(x = data_Mod$person_age)) +
      geom_histogram(fill = "lightblue", color = "white", bins = 30) +
      labs(title = paste("Distribución de", n), x = n, y = "Frecuencia") +
      theme_minimal()
```

```{r}
skewness(log(data_Mod$person_age - 19))
```

Vemos que aplicando esta transformación logarítmica, mejoramos la distribución de la variable 'person_age', 
ya que la edad mínima de las personas es 20 años, por tanto restamos 19 para evitar el logaritmo de 0.

```{r}
skewness(data_Mod$person_income)
```
```{r}	
ggplot(data_Mod, aes(x = data_Mod$person_income)) +
      geom_histogram(fill = "lightblue", color = "white", bins = 30) +
      labs(title = paste("Distribución de", n), x = n, y = "Frecuencia") +
      theme_minimal()
```

```{r}
skewness(log(data_Mod$person_income))
```

Vemos que aplicando esta transformación logarítmica, mejoramos la distribución de la variable 'person_income'.

- loan_amnt:

```{r}
skewness(data_Mod$loan_amnt)
```

Nos sale una asimetría de 1.17, por tanto tenemos que aplicar otra transformación.

```{r}
skewness(sqrt(data_Mod$loan_amnt))
skewness(log(data_Mod$loan_amnt))
```

Como podemos ver, ambos solucionan el problema de asimetría, pero la transformación con raíz cuadrada es más efectiva.

- loan_percent_income:

```{r}
skewness(data_Mod$loan_percent_income)
```

Nos sale una asimetría de 1.03, por tanto, es conveniente aplicar otra transformación.

```{r}
skewness(sqrt(data_Mod$loan_percent_income))
skewness(log(data_Mod$loan_percent_income))
```

Como podemos ver, ambos solucionan el problema de asimetría, pero la transformación con raíz cuadrada es más efectiva.

#### Creation of a better skewed dataset

Con todas las transformaciones realizadas, procedemos a crear un nuevo dataset con las variables transformadas, ya que siguen mejor la distribución normal:

```{r}
data_Transformed <- data_Mod

data_Transformed$person_age <- log(data_Mod$person_age - 19)
data_Transformed$person_income <- log(data_Mod$person_income)
data_Transformed$loan_amnt <- sqrt(data_Mod$loan_amnt)
data_Transformed$loan_percent_income <- sqrt(data_Mod$loan_percent_income)
```

## Model Building

### Ordenar las variables

```{r}
# Identificar las columnas numéricas y de tipo factor
numeric_columns <- sapply(data_Transformed, is.numeric)
factor_columns <- sapply(data_Transformed, is.factor)

# Excluir la variable objetivo de las columnas numéricas y de tipo factor
numeric_columns <- numeric_columns & names(data_Transformed) != "loan_status"

# Ordenar las columnas: primero las numéricas, luego las de tipo factor, y finalmente la variable objetivo
ordered_columns <- c(names(data_Transformed)[numeric_columns], 
                     names(data_Transformed)[factor_columns], 
                     "loan_status")

# Reordenar el data frame
data_Transformed <- data_Transformed[, ordered_columns]
```

### Data Normalization

```{r}
## create normalization function
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# Identificar las columnas numéricas
numerical_columns <- sapply(data_Transformed, is.numeric)

# Aplicar una transformación (por ejemplo, normalización) solo a las columnas numéricas
data_Normalized <- data_Transformed
## normalize the iris numerical data
data_Normalized[, numerical_columns] <- as.data.frame(lapply(data_Transformed[, numerical_columns], normalize))
## confirm that normalization worked
summary(data_Normalized)
```

### Train-Test Split

```{r}
# Convertir las variables categóricas en variables dummy
data_Normalized <- model.matrix(~ . - 1, data = data_Normalized)

# Convertir el resultado a un data frame
data_Normalized <- as.data.frame(data_Normalized)
```

```{r}
## To reproduce the calculations
seeds <- c(1357, 2468, 3579, 4680, 5791)
set.seed(seeds[1])

## Create an index to partition the data set
ind <- sample(2, nrow(data_Normalized), replace=TRUE, prob=c(0.80, 0.20))

data_Normalized.train <- data_Normalized[ind==1,]
data_Normalized.test <- data_Normalized[ind==2,]
```

Veamos que se hayan hecho bien las particiones

```{r}
nrow(data_Normalized)
nrow(data_Normalized.train)
nrow(data_Normalized.test)
```

## Classification using Nearest Neighbors

### Predictions

```{r}
## Build the classifier
data_Normalized.knn <- knn(data_Normalized.train[, 1:19], data_Normalized.test[, 1:19], cl = data_Normalized.train[, 20], k = 3)
```

```{r}
CrossTable(x = data_Normalized.test$loan_status, y = data_Normalized.knn, prop.chisq=FALSE)
```

Desde la tabla podemos ver que el modelo en lineas generales es preciso, con un margen de error del 0.135 (precisión del 86.5%). Por otro lado, si nos fijamos
en la columna de aceptados, la precisión es del 0.658, un valor bastante bajo. Esto quiere decir que este modelo puede ser mas propenso a rechazar préstamos a esas muestras donde debería aceptarlos.

Probaremos solo utilizando las variables numéricas a ver como se comporta el modelo.

```{r}
## Build the classifier
data_Normalized.knn2 <- knn(data_Normalized.train[, 1:4], data_Normalized.test[, 1:4], cl = data_Normalized.train[, 20], k = 3)
CrossTable(x = data_Normalized.test$loan_status, y = data_Normalized.knn2, prop.chisq=FALSE)
```

Como se puede ver, el modelo es menos preciso, lo que tiene sentido ya que las variables categóricas también influyen en la decisión de si se aprueba o no un préstamo.

Ahora probaremos esta vez con 2 ks diferentes, 5 y 2.

```{r}
## Build the classifier
data_Normalized.knn3 <- knn(data_Normalized.train[, 1:19], data_Normalized.test[, 1:19], cl = data_Normalized.train[, 20], k = 2)
data_Normalized.knn4 <- knn(data_Normalized.train[, 1:19], data_Normalized.test[, 1:19], cl = data_Normalized.train[, 20], k = 5)
CrossTable(x = data_Normalized.test$loan_status, y = data_Normalized.knn3, prop.chisq=FALSE)
CrossTable(x = data_Normalized.test$loan_status, y = data_Normalized.knn4, prop.chisq=FALSE)
```

## Classification using Naive Bayes

```{r}
classifier.NB <- naiveBayes(x = data_Normalized.train[, 1:19], y = data_Normalized.train[, 20])
data_Normalized.NB <- predict(classifier.NB, data_Normalized.test[, 1:19])

CrossTable(x = data_Normalized.test$loan_status, y = data_Normalized.NB, prop.chisq=FALSE)
```

## Classification using Decision Trees

### ID3 Algorithm

```{r}
## Create an index to partition the data set
ind <- sample(2, nrow(data_Mod), replace=TRUE, prob=c(0.80, 0.20))

data_Mod.train <- data_Mod[ind==1,]
data_Mod.test <- data_Mod[ind==2,]
```

```{r}
# Crear el modelo, con todas las variables
ID3 <- J48(loan_status ~ person_age, data = data_Mod.train)
plot(ID3)
```

```{r}
tree(Species ~ Sepal.Width + Petal.Width, data = iris)
data_Transformed.tree <- tree(Species ~ Sepal.Width + Petal.Width, data = iris)
```

### C5.0 Algorithm

```{r}
library(C50)
```

```{r}
classifier.C50 <- C5.0(iris.train[,1:4], iris.train[,5])
classifier.C50
```





